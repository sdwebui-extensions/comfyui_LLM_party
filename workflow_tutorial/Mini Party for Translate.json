{
  "last_node_id": 24,
  "last_link_id": 29,
  "nodes": [
    {
      "id": 24,
      "type": "Note",
      "pos": {
        "0": 1730,
        "1": 1180
      },
      "size": [
        370,
        150
      ],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Note",
      "properties": {},
      "widgets_values": [
        "#关于我们：\n- LLM_Party正在用心经营一片AI时代的后花园，我们希望能够在AI时代下成为众多参与者的一员，我们从开源社区中走来，也希望回到社区中去。\n- 欢迎大家来到我们用心经营的后花园。如果我们的项目能够帮助到大家，麻烦大家在Github上帮我点一下Star：\n- github项目地址：https://github.com/heshengtao/comfyui_LLM_party\n- openart：https://openart.ai/workflows/profile/comfyui_llm_party?tab=workflows&sort=latest\n- LibLib：https://www.liblib.art/userpage/4378612c5b3341c79c0deab3101aeabb/publish/workflow\n- 哔哩哔哩：https://space.bilibili.com/26978344?spm_id_from=333.337.0.0\n- YouTube：https://www.youtube.com/@comfyui-LLM-party\n- discord：https://discord.com/invite/gxrQAYy6\n- QQ交流群：931057213\n- 微信交流群：Choo-Yong（添加小助理微信，统一通过后会添加至交流群）\n商务合作请联系email：hst97@qq.com"
      ]
    },
    {
      "id": 23,
      "type": "Note",
      "pos": {
        "0": 1730,
        "1": 880
      },
      "size": [
        370,
        210
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Note",
      "properties": {},
      "widgets_values": [
        "【加载文件】\n- 输入文件的绝对路径：C:\\Users\\YourUsername\\Documents\\example.txt\n- 也可以将【加载文件】节点换成【输入字符串】节点，将需要翻译的内容连接到（input_str）上。\n\n【迷你长文翻译器】\n- [target_language]：输入目标翻译语言；\n- [tone]：翻译内容的风格；\n- [degree]：范围1~10，数值越高越遵循翻译风格；\n- [model_name]：参考API model配置方法。（mini系列节点目前只支持api调用LLM）"
      ]
    },
    {
      "id": 21,
      "type": "load_file",
      "pos": {
        "0": 980,
        "1": 880
      },
      "size": {
        "0": 320,
        "1": 110
      },
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "file_content",
          "type": "STRING",
          "links": [
            28
          ],
          "shape": 3,
          "label": "file_content",
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "load_file"
      },
      "widgets_values": [
        "/hy-tmp/ComfyUI/custom_nodes/comfyui_LLM_party/README.md",
        "test.txt",
        true
      ]
    },
    {
      "id": 20,
      "type": "mini_translate",
      "pos": {
        "0": 980,
        "1": 1090
      },
      "size": [
        320,
        230
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [
        {
          "name": "input_str",
          "type": "STRING",
          "link": 28,
          "widget": {
            "name": "input_str"
          }
        }
      ],
      "outputs": [
        {
          "name": "output_str",
          "type": "STRING",
          "links": [
            29
          ],
          "shape": 3,
          "label": "output_str",
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "mini_translate"
      },
      "widgets_values": [
        "",
        "中文",
        "正式",
        5,
        "gpt-4o-mini",
        "",
        "",
        true
      ]
    },
    {
      "id": 22,
      "type": "show_text_party",
      "pos": {
        "0": 1330,
        "1": 880
      },
      "size": [
        370,
        440
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [
        {
          "name": "text",
          "type": "STRING",
          "link": 29,
          "widget": {
            "name": "text"
          }
        }
      ],
      "outputs": [
        {
          "name": "STRING",
          "type": "STRING",
          "links": null,
          "shape": 6,
          "label": "STRING"
        }
      ],
      "properties": {
        "Node name for S&R": "show_text_party"
      },
      "widgets_values": [
        "",
        "![图片](img/封面.png)\n\n<div align=\"center\">\n  <a href=\"https://space.bilibili.com/26978344\">视频教程</a> ·\n  <a href=\"how_to_use_nodes.md\">文字教程</a> ·\n  <a href=\"workflow_tutorial/\">工作流教程</a> ·\n  <a href=\"https://pan.baidu.com/share/init?surl=T4aEB4HumdJ7iVbvsv1vzA&pwd=qyhu\">百度云</a> ·\n  <a href=\"img/Q群.jpg\">QQ群</a> ·\n  <a href=\"https://discord.gg/gxrQAYy6\">Discord</a> ·\n  <a href=\"https://dcnsxxvm4zeq.feishu.cn/wiki/IyUowXNj9iH0vzk68cpcLnZXnYf\">关于我们</a>  \n</div>\n\n####\n\n<div align=\"center\">\n  <a href=\"./README_ZH.md\"><img src=\"https://img.shields.io/badge/简体中文-d9d9d9\"></a>\n  <a href=\"./README.md\"><img src=\"https://img.shields.io/badge/English-d9d9d9\"></a>\n  <a href=\"./README_RU.md\"><img src=\"https://img.shields.io/badge/Русский-d9d9d9\"></a>\n  <a href=\"./README_FR.md\"><img src=\"https://img.shields.io/badge/Français-d9d9d9\"></a> \n  <a href=\"./README_DE.md\"><img src=\"https://img.shields.io/badge/Deutsch-d9d9d9\"></a>\n  <a href=\"./README_JA.md\"><img src=\"https://img.shields.io/badge/日本語-d9d9d9\"></a>\n  <a href=\"./README_KO.md\"><img src=\"https://img.shields.io/badge/한국어-d9d9d9\"></a>\n  <a href=\"./README_AR.md\"><img src=\"https://img.shields.io/badge/العربية-d9d9d9\"></a>\n  <a href=\"./README_ES.md\"><img src=\"https://img.shields.io/badge/Español-d9d9d9\"></a>\n  <a href=\"./README_PT.md\"><img src=\"https://img.shields.io/badge/Português-d9d9d9\"></a>\n</div>\n\n####\n\ncomfyui_llm_party旨在基于[comfyui](https://github.com/comfyanonymous/ComfyUI)作为前端开发一整套用于构建LLM工作流的节点。该工具允许用户快速且便捷地搭建自己的LLM工作流，并轻松与现有的图像工作流进行整合。\n\n## 效果展示\nhttps://github.com/user-attachments/assets/945493c0-92b3-4244-ba8f-0c4b2ad4eba6\n\n## 项目概览ComfyUI LLM Party，从最基础的LLM多工具调用、角色设置，迅速构建您专属的AI助手，到面向行业的词向量RAG和GraphRAG，实现行业知识库的本地化管理；从单一代理管道到复杂代理间径向交互模式和环状交互模式的构建；从个人用户所需的社交应用接入（如QQ、飞书、Discord），到流媒体工作者所需的一站式LLM + TTS + ComfyUI工作流程；从普通学生所需的首个LLM应用的简单启动，到科研人员常用的各种参数调试接口以及模型适配。在ComfyUI LLM Party，您都能找到答案。## 最新更新\n1. **重要更新！！！** 现在您可以将任何 ComfyUI 工作流封装为 LLM 工具节点。您可以让 LLM 同时控制多个 ComfyUI 工作流。当您希望其完成某些任务时，LLM 可以根据您的提示选择合适的 ComfyUI 工作流，完成任务后将结果返回给您。示例工作流：[comfyui_workflows_tool](workflow/把任意workflow当作LLM_tool.json)。具体步骤如下：\n   - 首先，将您希望封装为工具的工作流的文本输入接口连接至“开始工作流”节点的“用户提示”输出。这是 LLM 调用工具时传入提示的地方。\n   - 将您希望输出文本和图像的位置连接到“结束工作流”节点的相应输入位置。\n   - 将此工作流保存为 API（您需要在设置中启用开发者模式以查看此按钮）。\n   - 将此工作流保存至该项目的 workflow_api 文件夹中。\n   - 重启 ComfyUI，并创建一个简单的 LLM 工作流，例如：[start_with_LLM_api](workflow/start_with_LLM_api.json)。\n   - 向此 LLM 节点添加一个“工作流工具”节点，并将其连接至 LLM 节点的工具输入。\n   - 在“工作流工具”节点中，在第一个输入框中写入您希望调用的工作流文件名，例如：draw.json。您可以写入多个工作流文件名。在第二个输入框中，写入每个工作流的功能，以便 LLM 理解如何使用这些工作流。- 运行该程序以查看大语言模型调用您封装的工作流程并将结果返回给您。如果返回的是图像，请将“预览图像”节点连接到LLM节点的图像输出，以查看生成的图像。注意！该方法将在您的8190端口上呼叫一个新的ComfyUI，请勿占用此端口。在Windows和Mac系统上，将打开一个新的终端，请勿关闭它。Linux系统则使用屏幕进程来实现这一点，当您不再需要使用时，请关闭该屏幕进程，否则它将始终占用您的端口。\n\n![workflow_tool](img/workflowtool.png)## 用户指南\n1. 有关节点使用说明，请参考: [如何使用节点](how_to_use_nodes.md)\n\n2. 如果您在插件使用中遇到任何问题或有其他疑问，请随时加入QQ群: [931057213](img/Q群.jpg)。\n\n3. 请参考工作流程教程: [工作流程教程](workflow_tutorial/)，感谢[HuangYuChuh](https://github.com/HuangYuChuh)的贡献！\n\n4. 高级工作流程玩法账户：[openart](https://openart.ai/workflows/profile/comfyui_llm_party?sort=latest&tab=creation)\n\n5. 更多工作流程请参考[工作流程](workflow)文件夹。\n\n## 视频教程\n1. [用ComfyUI×LLM构建模块化AI：一步一步教程（超级简单！）](https://www.bilibili.com/video/BV1JZ421v7Tw/?vd_source=f229e378448918b84afab7c430c6a75b)\n\n2. [教您如何使用GPT-4o访问comfyui | 使工作流程能够调用另一工作流程 | 让LLM成为工具](https://www.bilibili.com/video/BV1JJ4m1A789/?spm_id_from=333.999.0.0&vd_source=f229e378448918b84afab7c430c6a75b)\n\n3. [将您的工作流程伪装成GPT以访问微信 | Omost兼容性极强！灵活创建您自己的dalle3](https://www.bilibili.com/video/BV1DT421a7KY/?spm_id_from=333.999.0.0)\n\n4. [如何在comfyui中玩互动小说游戏](https://www.bilibili.com/video/BV15y411q78L/?spm_id_from=333.999.0.0&vd_source=f229e378448918b84afab7c430c6a75b)\n\n5. [AI女友以及您的形象 | comfyui实现graphRAG，链接neoa4j | comfyui工作流程访问streamlit前端](https://www.bilibili.com/video/BV1dS421R7Au/?spm_id_from=333.999.0.0&vd_source=f229e378448918b84afab7c430c6a75b)## 模型支持\n1. 支持以 OpenAI 格式进行的所有 API 调用（结合 [oneapi](https://github.com/songquanpeng/one-api)，几乎可以调用所有 LLM API，也支持所有中转 API），base_url 选择参考 [config.ini.example](config.ini.example)，到目前为止已测试的包括：\n* [openai](https://platform.openai.com/docs/api-reference/chat/create)（与所有 OpenAI 模型完美兼容，包括 4o 和 o1 系列！）\n* [ollama](https://github.com/ollama/ollama)（推荐！如果您是在本地调用，强烈建议使用 ollama 方法来托管您的本地模型！）\n* [llama.cpp](https://github.com/ggerganov/llama.cpp?tab=readme-ov-file#web-server)（推荐！如果您希望使用本地 gguf 格式模型，可以使用 llama.cpp 项目的 API 来访问此项目！）\n* [通义千问 /qwen](https://help.aliyun.com/zh/dashscope/developer-reference/compatibility-of-openai-with-dashscope/?spm=a2c4g.11186623.0.0.7b576019xkArPq)\n* [智谱青言/glm](https://open.bigmodel.cn/dev/api#http_auth)\n* [deepseek](https://platform.deepseek.com/api-docs/zh-cn/)\n* [kimi/moonshot](https://platform.moonshot.cn/docs/api/chat#%E5%9F%BA%E6%9C%AC%E4%BF%A1%E6%81%AF)\n* [doubao](https://www.volcengine.com/docs/82379/1263482)\n\n2. 支持 Gemini 格式的 API 调用：\n* [Gemini](https://aistudio.google.com/app/prompts/new_chat)3. 与变压器库中的大多数本地模型兼容（本地LLM模型链节点上的模型类型已更改为LLM、VLM-GGUF和LLM-GGUF，分别对应于直接加载LLM模型、加载VLM模型和加载GGUF格式LLM模型）。如果您的VLM或GGUF格式LLM模型报告错误，请从 [llama-cpp-python](https://github.com/abetlen/llama-cpp-python/releases) 下载最新版本的 llama-cpp-python。当前测试的模型包括：\n* [ClosedCharacter/Peach-9B-8k-Roleplay](https://huggingface.co/ClosedCharacter/Peach-9B-8k-Roleplay)(推荐！角色扮演模型)\n* [omost-llama-3-8b-4bits](https://huggingface.co/lllyasviel/omost-llama-3-8b-4bits)(推荐！丰富提示模型)\n* [meta-llama/llama-2-7b-chat-hf](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf)\n* [Qwen/Qwen2-7B-Instruct](https://huggingface.co/Qwen/Qwen2-7B-Instruct)\n* [xtuner/llava-llama-3-8b-v1_1-gguf](https://huggingface.co/xtuner/llava-llama-3-8b-v1_1-gguf)\n* [lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF](https://huggingface.co/lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/tree/main)\n* [meta-llama/Llama-3.2-11B-Vision-Instruct](https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct)\n\n4. 模型下载\n* [百度云地址](https://pan.baidu.com/share/init?surl=T4aEB4HumdJ7iVbvsv1vzA&pwd=qyhu)，提取码：qyhu\n\n## 下载\n* 您可以在 `config.ini` 中配置语言，目前仅支持中文（zh_CN）和英文（en_US），默认语言为您的系统语言。\n* 使用以下任一方法进行安装：\n### 方法 1：\n1. 在 [comfyui manager](https://github.com/ltdrdata/ComfyUI-Manager) 中搜索 comfyui_LLM_party 并一键安装。\n2. 重启 comfyui。\n\n### 方法 2：\n1. 进入 ComfyUI 根文件夹下的 `custom_nodes` 子文件夹。\n2. 使用 `git clone https://github.com/heshengtao/comfyui_LLM_party.git` 克隆该仓库。### 方法三：\n1. 点击右上角的 `CODE`。\n2. 点击 `download zip`。\n3. 将下载的压缩包解压至 ComfyUI 根目录下的 `custom_nodes` 子文件夹中。\n\n## 环境部署\n1. 导航到 `comfyui_LLM_party` 项目文件夹。\n2. 在终端输入 `pip install -r requirements.txt`，将项目所需的第三方库部署到 comfyui 环境中。请确保您在 comfyui 环境中进行安装，并注意终端中的任何 `pip` 错误。\n3. 如果您使用的是 comfyui 启动器，需要在终端输入 `path_in_launcher_configuration\\python_embeded\\python.exe -m pip install -r requirements.txt` 进行安装。`python_embeded` 文件夹通常与您的 `ComfyUI` 文件夹处于同一层级。\n4. 如果您遇到环境配置问题，可以尝试使用 `requirements_fixed.txt` 中的依赖项。\n\n## 配置\nAPIKEY 可通过以下方法之一进行配置。\n### 方法一：\n1. 打开 `comfyui_LLM_party` 项目文件夹中的 `config.ini` 文件。\n2. 在 `config.ini` 中输入您的 openai_api_key 和 base_url。\n3. 如果您使用的是 ollama 模型，请在 `base_url` 中填写 `http://127.0.0.1:11434/v1/`，在 `openai_api_key` 中填写 `ollama`，在 `model_name` 中填写您的模型名称，例如：`llama3`。\n4. 如果您想使用 Google 搜索或 Bing 搜索工具，请在 `config.ini` 中输入您的 `google_api_key`、`cse_id` 或 `bing_api_key`。\n5. 如果您希望使用图像输入 LLM，建议使用图像床 imgbb，并在 `config.ini` 中输入您的 imgbb_api。\n6. 每个模型可以在 `config.ini` 文件中单独配置，可以参考 `config.ini.example` 文件进行填写。配置完成后，仅需在节点上输入 `model_name`。### 方法二：\n1. 打开 comfyui 界面。\n2. 创建一个大型语言模型（LLM）节点，并直接在节点中输入您的 openai_api_key 和 base_url。\n3. 如果您使用 ollama 模型，请使用 LLM_api 节点，在 `base_url` 节点中填写 `http://127.0.0.1:11434/v1/`，在 `api_key` 中填写 `ollama`，并在 `model_name` 中填写您的模型名称，例如：`llama3`。\n4. 如果您希望使用图像输入的 LLM，建议使用 graph bed imgbb，并在节点中输入您的 `imgbb_api_key`。## 更新日志\n1. 您可以在 ComfyUI 界面中右键点击，选择上下文菜单中的 `llm`，您将找到该项目的节点。[如何使用节点](how_to_use_nodes.md)\n2. 支持 API 集成或本地大型模型集成。工具调用的模块化实现。在输入 base_url 时，请确保使用以 `/v1/` 结尾的 URL。您可以使用 [ollama](https://github.com/ollama/ollama) 来管理您的模型。然后，输入 `http://127.0.0.1:11434/v1/` 作为 base_url，`ollama` 作为 api_key，以及您的模型名称，例如：llama3。\n   - API 访问示例工作流：[使用 LLM API 开始](workflow/start_with_LLM_api)\n   - 本地模型访问示例工作流：[使用 LLM 本地开始](workflow/start_with_LLM_local)\n   - ollama 访问示例工作流：[ollama](workflow/ollama.json)\n3. 集成本地知识库，支持 RAG。示例工作流：[知识库 RAG 搜索](workflow/知识库RAG搜索.json)\n4. 支持调用代码解释器。\n5. 启用在线查询，包括 Google 搜索支持。示例工作流：[电影查询工作流](workflow/电影查询工作流.json)\n6. 在 ComfyUI 中实现条件语句，以对用户查询进行分类并提供针对性响应。示例工作流：[智能客服](workflow/智能客服.json)\n7. 支持大型模型的循环链接，使两个大型模型能够进行辩论。示例工作流：[电车难题辩论赛](workflow/电车难题辩论赛.json)\n8. 附加任意角色面具，自定义提示模板。\n9. 支持多种工具调用，包括天气查询、时间查询、知识库、代码执行、网页搜索和单页搜索。\n10. 将 LLM 作为工具节点使用。示例工作流：[LLM 套娃](workflow/LLM套娃.json)\n11. 利用 API + Streamlit 快速开发您自己的网页应用程序。\n12. 新增一个危险的全能解释器节点，允许大型模型执行任何任务。13. 推荐在右键菜单的“功能”子菜单中使用`show_text`节点作为LLM节点的展示输出。\n14. 支持GPT-4O的视觉特性！示例工作流：[GPT-4o](workflow/GPT-4o.json)\n15. 新增了一种工作流中介，允许您的工作流调用其他工作流！示例工作流：[调用另一个工作流](workflow/调用另一个工作流.json)\n16. 适配了所有与OpenAI接口相似的模型，如：通义千问/QWEN、知谷轻言/GLM、深度探索、Kimi/Moonshot。请将这些模型的base_url、api_key和model_name填写至LLM节点以进行调用。\n17. 添加了LVM加载器，现在您可以在本地调用LVM模型，支持[lava-llama-3-8b-v1_1-gguf](https://huggingface.co/xtuner/llava-llama-3-8b-v1_1-gguf)模型，理论上其他GGUF格式的LVM模型也应能运行。示例工作流可在此寻找：[start_with_LVM.json](workflow/start_with_LVM.json)。\n18. 我编写了一个`fastapi.py`文件，如果直接运行，您将在`http://127.0.0.1:8817/v1/`上获得一个OpenAI接口。现在任何能够调用GPT的应用程序都可以调用您的comfyui工作流！我将创建一个教程来详细演示如何操作。\n19. 我将LLM加载器与LLM链分离，区分了模型加载和模型配置。这允许在不同的LLM节点之间共享模型！\n20. 现在支持macOS和mps设备！感谢[bigcat88](https://github.com/bigcat88)的贡献！\n21. 您可以构建自己的互动小说游戏，并根据用户的选择前往不同的结局！示例工作流参考：[互动小说](workflow/互动小说.json)\n22. 适配了OpenAI的whisper和tts功能，可以实现语音输入和输出。示例工作流参考：[语音输入+语音输出](workflow/语音输入+语音输出.json)23. 兼容于 [Omost](https://github.com/lllyasviel/Omost)！！！请下载 [omost-llama-3-8b-4bits](https://huggingface.co/lllyasviel/omost-llama-3-8b-4bits) 来立即体验！示例工作流程参考：[start_with_OMOST](workflow/start_with_OMOST)  \n24. 增加了LLM工具，可发送消息至WeCom、钉钉及飞书，并支持调用外部功能。  \n25. 新增了一种文本迭代器，该迭代器可以一次仅输出部分字符。文本可依据回车符和块大小安全地分割，不会从文本中间断开。chunk_overlap指的是分割文本重叠的字符数。通过这种方式，您可以批量输入超长文本，只要不需要手动点击，或在comfyui中开启循环执行即可，这将会自动执行。请记得开启is_locked属性，这可以使工作流程在输入结束时自动锁定，且不再继续执行。示例工作流程：[text iteration input](workflow/文本迭代输入.json)  \n26. 为本地LLM加载器和本地llava加载器新增了模型名称属性。若该属性为空，将使用节点中的多条本地路径加载；若不为空，将根据您在`config.ini`中填写的路径参数进行加载。若该属性不为空且不在`config.ini`中，则将从huggingface下载或从huggingface的模型保存目录加载。若希望从huggingface下载，请填写格式如：`THUDM/glm-4-9b-chat`。注意！以这种方式加载的模型必须适配transformer库。  \n27. 新增了JSON文件解析节点和JSON值节点，允许您从文件或文本中获取键的值。感谢 [guobalove](https://github.com/guobalove) 的贡献！28. 改进了工具调用的代码。现在没有工具调用功能的语言模型（LLM）也能够开启is_tools_in_sys_prompt属性（本地LLM默认不需要开启，自动适应）。开启后，工具信息将被添加至系统提示词中，以便LLM可以调用该工具。相关实现原理的论文：[利用仅凭提示工程实现LLM的工具调用功能，无需微调](https://arxiv.org/abs/2407.04997)\n\n29. 创建了一个新的custom_tool文件夹，用于存放自定义工具的代码。您可以参考[custom_tool](custom_tool)文件夹中的代码，将自定义工具的代码放入custom_tool文件夹，从而在LLM中调用该自定义工具。\n\n30. 添加了知识图谱工具，使得LLM与知识图谱能够完美互动。LLM可以根据您的输入修改知识图谱，并在知识图谱上进行推理，以获取所需答案。示例工作流程参考：[graphRAG_neo4j](workflow/graphRAG_neo4j.json)\n\n31. 添加了个性AI功能，无需代码即开发您自己的女友AI或男友AI，支持无限对话、永久记忆与稳定性格。示例工作流程参考：[Mylover Personality AI](workflow/麦洛薇人格AI.json)\n\n32. 您可以使用该LLM工具制造机自动生成LLM工具，将您生成的工具代码保存为Python文件，然后将代码复制到custom_tool文件夹中，再创建一个新节点。示例工作流程：[LLM工具制造机](workflow/LLM工具制造机.json)。\n\n33. 支持duckduckgo搜索，但存在显著限制。似乎只能输入英文关键词，且关键词中不能出现多个概念。其优势在于没有API密钥限制。\n\n34. 支持分别调用多个知识库的功能，可以在提示语中指定使用哪一个知识库来回答问题。示例工作流程：[多知识库分别调用](workflow/多知识库分别调用.json)。35. 支持LLM输入的额外参数，包括如json输出等高级参数。示例工作流：[LLM输入额外参数](workflow/LLM额外参数eg_JSON_OUT.json)。[用json_out分离提示词](workflow/用json_out分离提示词.json)。\n36. 增加了将代理连接至Discord的功能。（仍在测试中）\n37. 增加了将代理连接至飞书的功能，特别感谢[guobalove](https://github.com/guobalove)的贡献！请参阅工作流：[飞书机器人](workflow/飞书机器人.json)。\n38. 增加了通用API调用节点和大量辅助节点，用于构建请求体和获取响应中的信息。\n39. 增加了空模型节点，您可以在任何位置卸载视频内存中的LLM！\n40. 新增了[chatTTS](https://github.com/2noise/ChatTTS)节点，感谢[guobalove](https://github.com/guobalove)的贡献！`model_path`参数可以为空！建议使用`HF`模式加载模型，模型将自动从Hugging Face下载，无需手动下载；如果使用`local`加载，请将模型的`asset`和`config`文件夹放置于根目录。[百度云地址](https://pan.baidu.com/share/init?surl=T4aEB4HumdJ7iVbvsv1vzA&pwd=qyhu)，提取码：qyhu；如果使用`custom`模式加载，请将模型的`asset`和`config`文件夹放置在`model_path`下。\n2. 更新了一系列转换节点：markdown转HTML，svg转图片，HTML转图片，mermaid转图片，markdown转Excel。\n1. 兼容llama3.2视觉模型，支持多轮对话及视觉功能。模型地址：[meta-llama/Llama-3.2-11B-Vision-Instruct](https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct)。示例工作流：[llama3.2_vision](https://github.com/heshengtao/comfyui_LLM_party/blob/main/workflow_tutorial/LLM_Party%20for%20Llama3.2%20-Vision%EF%BC%88%E5%B8%A6%E8%AE%B0%E5%BF%86%EF%BC%89.json)。1. 调整了GOT-OCR2，支持格式化输出结果，支持使用位置框和颜色进行精细文本识别。模型地址：[GOT-OCR2](https://huggingface.co/stepfun-ai/GOT-OCR2_0)。示例工作流将网页截图转换为HTML代码，并打开浏览器显示该网页：[img2web](workflow/图片转网页.json)。\n\n2. 本地LLM加载节点已大幅调整，因此您无需再自行选择模型类型。llava加载节点和GGUF加载节点已重新添加。本地LLM模型链节点的模型类型已更改为LLM、VLM-GGUF和LLM-GGUF，分别对应直接加载LLM模型、加载VLM模型和加载GGUF格式LLM模型。VLM模型和GGUF格式LLM模型现已再次得到支持。本地调用现在可以兼容更多模型！示例工作流：[LLM_local](workflow/start_with_LLM_local.json)、[llava](workflow/start_with_llava.json)、[GGUF](workflow/start_with_GGUF.json)。\n\n3. 新增EasyOCR节点，用于识别图像中的文本和位置。它能够生成相应的掩模，并返回JSON字符串供LLM查看。现有标准版和高级版供大家选择！\n\n4. 在comfyui LLM派对中，重新制作了chatgpt-o1系列模型的草莓系统，参考了[Llamaberry](https://huggingface.co/spaces/martinbowling/Llamaberry/blob/main/app.py)的提示。示例工作流：[草莓系统与o1对比](workflow/草莓系统与o1对比.json)。2. 新增了一个 GPT-sovits 节点，您可以调用 GPT-sovits 模型，根据您的参考音频将文本转换为语音。您还可以填写经过微调的模型路径（若未填写，将使用基础模型进行推理）以获取所需的声音。使用该功能时，您需要在本地下载 [GPT-sovits](https://github.com/RVC-Boss/GPT-SoVITS) 项目及其相应的基础模型，然后在 GPT-sovits 项目文件夹中通过 `runtime\\python.exe api_v2.py` 启动 API 服务。此外，chatTTS 节点已迁移至 [comfyui LLM mafia](https://github.com/heshengtao/comfyui_LLM_mafia)。原因在于 chatTTS 具有较多依赖项，并且其在 PyPi 上的许可证为 CC BY-NC 4.0，这是一种非商业许可证。尽管 chatTTS GitHub 项目采用 AGPL 许可证，我们仍将 chatTTS 节点迁移到 comfyui LLM mafia，以避免不必要的麻烦。希望大家能够理解！\n\n3. 现在支持 OpenAI 的最新模型 o1 系列！\n\n4. 新增了本地文件控制工具，允许 LLM 控制您指定文件夹中的文件，例如读取、写入、追加、删除、重命名、移动和复制文件。由于此节点的潜在风险，它被纳入 [comfyui LLM mafia](https://github.com/heshengtao/comfyui_LLM_mafia)。\n\n5. 新增 SQL 工具，允许 LLM 查询 SQL 数据库。\n\n6. 更新了多语言版本的 README。翻译 README 文档的工作流程： [translate_readme](workflow/文档自动翻译机.json)\n\n7. 更新了 4 个迭代器节点（文本迭代器、图片迭代器、Excel 迭代器、JSON 迭代器）。迭代器模式包括：顺序、随机和无限。顺序模式将按照序列输出，直到超出索引限制，过程将自动中止，索引值将重置为 0。随机模式将选择一个随机索引输出，而无限模式将循环输出。8. 新增了Gemini API加载节点，现在与Gemini官方API兼容！由于在工具调用过程中，如果返回的参数包含中文字符，Gemini将生成返回代码为500的错误，因此某些工具节点不可用。示例工作流程：[start_with_gemini](workflow/start_with_gemini.json)  \n9. 新增了背景故事节点，您可以在与大型语言模型对话时插入您的背景设置，示例工作流程：[lorebook](workflow/lorebook.json)  \n10. 新增FLUX提示词生成器掩码节点，可以生成《炉石传说》卡片、《游戏王》卡片、海报、漫画等风格的提示词，从而使FLUX模型直接输出。参考工作流程：[FLUX提示词](https://openart.ai/workflows/comfyui_llm_party/flux-by-llm-party/sjME541i68Kfw6Ib0EAD)  ## 后续计划：\n1. 更多模型适配，至少涵盖主流大模型的API接口以及主流开源模型的本地调用，同时增加更多的LVM模型适配。目前，我仅完成了对GPT-4视觉功能调用的适配；\n2. 更多构建代理的方法。我在这一领域完成的工作包括将一个LLM作为工具导入到另一个LLM，实现LLM工作流的径向构建，以及将一个工作流作为节点导入到另一个工作流中。未来我可能会在这方面开发一些更酷的功能；\n3. 更多自动化功能。未来我将引入更多自动推送图像、文本、视频和音频到其他应用程序的节点，以及实现对主流社交软件和论坛进行自动回复的监听节点；\n4. 更多知识库管理功能。该项目已经支持本地文件搜索和网页搜索。未来，我将引入知识图谱搜索和长期记忆搜索。这将使代理能够在与用户对话时逻辑性地思考专业知识，并始终记住某些关键信息；\n5. 更多工具，更多个性化。这一部分是最容易实现的，但也需要最多的积累。我希望在未来，这个项目可以拥有与comfyui一样多的自定义节点，配备大量的工具和个性化选项。\n\n## 免责声明：\n本开源项目及其内容（以下简称“项目”）仅供参考，且不暗示任何形式的保证，无论是明示还是暗示。项目的贡献者对项目的完整性、准确性、可靠性或适用性不承担任何责任。您对项目的任何依赖均须自担风险。在任何情况下，项目的贡献者皆不对因使用项目而产生的任何间接、特殊或附带损害，或任何形式的损害承担责任。## 特别感谢：\n<a href=\"https://github.com/bigcat88\">\n  <img src=\"https://avatars.githubusercontent.com/u/13381981?v=4\" width=\"50\" height=\"50\" style=\"border-radius: 50%; overflow: hidden;\" alt=\"octocat\"/>\n</a>\n<a href=\"https://github.com/guobalove\">\n  <img src=\"https://avatars.githubusercontent.com/u/171540731?v=4\" width=\"50\" height=\"50\" style=\"border-radius: 50%; overflow: hidden;\" alt=\"octocat\"/>\n</a>\n<a href=\"https://github.com/HuangYuChuh\">\n  <img src=\"https://avatars.githubusercontent.com/u/167663109?v=4\" width=\"50\" height=\"50\" style=\"border-radius: 50%; overflow: hidden;\" alt=\"octocat\"/>\n</a>\n\n## 借用清单 \n本项目中的部分节点借用了以下项目。感谢您对开源社区的贡献！\n1. [pythongosssss/ComfyUI-Custom-Scripts](https://github.com/pythongosssss/ComfyUI-Custom-Scripts)\n2. [lllyasviel/Omost](https://github.com/lllyasviel/Omost)\n\n## 支持：\n\n### 加入社区\n如您在使用插件时遇到问题或有其他疑问，欢迎加入我们的社区。\n\n1. Discord: [discord 链接](https://discord.gg/gxrQAYy6)\n2. QQ 群：`931057213`\n\n<div style=\"display: flex; justify-content: center;\">\n    <img src=\"img/Q群.jpg\" style=\"width: 48%;\" />\n</div>\n\n3. 微信群：`Choo-Yong`（添加小助手微信后进入群组）\n\n### 关注我们\n1. 如您希望继续关注本项目的最新功能，请关注 Bilibili 账号：[Party host BB machine](https://space.bilibili.com/26978344)\n2. OpenArt 账号持续更新最有用的派对工作流程：[openart](https://openart.ai/workflows/profile/comfyui_llm_party?sort=latest&tab=creation)### 捐赠支持\n如果我的工作给您带来了价值，考虑以一杯咖啡来支持我吧！您的支持不仅能为项目注入活力，也能温暖创作者的心。☕💖 每一杯都能产生影响！\n<div style=\"display:flex; justify-content:space-between;\">\n    <img src=\"img/zhifubao.jpg\" style=\"width: 48%;\" />\n    <img src=\"img/wechat.jpg\" style=\"width: 48%;\" />\n</div>\n\n## 星标历史\n\n[![星标历史图表](https://api.star-history.com/svg?repos=heshengtao/comfyui_LLM_party&type=Date)](https://star-history.com/#heshengtao/comfyui_LLM_party&Date)"
      ]
    }
  ],
  "links": [
    [
      28,
      21,
      0,
      20,
      0,
      "STRING"
    ],
    [
      29,
      20,
      0,
      22,
      0,
      "STRING"
    ]
  ],
  "groups": [
    {
      "title": "About Us",
      "bounding": [
        1720,
        1110,
        390,
        220
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "title": "Output",
      "bounding": [
        1320,
        810,
        390,
        520
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "title": "Load Files",
      "bounding": [
        970,
        810,
        340,
        200
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "title": "Translate",
      "bounding": [
        970,
        1020,
        340,
        314
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "title": "Mini Party for Translate",
      "bounding": [
        970,
        650,
        1140,
        150
      ],
      "color": "#3f789e",
      "font_size": 110,
      "flags": {}
    },
    {
      "title": "Note",
      "bounding": [
        1720,
        810,
        390,
        290
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    }
  ],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.9849732675807673,
      "offset": [
        -678.7544418947236,
        -559.6193676101401
      ]
    }
  },
  "version": 0.4
}